<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Laboratorio 7</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Lab7_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lab7_files/libs/quarto-html/quarto.js"></script>
<script src="Lab7_files/libs/quarto-html/popper.min.js"></script>
<script src="Lab7_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Lab7_files/libs/quarto-html/anchor.min.js"></script>
<link href="Lab7_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lab7_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Lab7_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Lab7_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Lab7_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Laboratorio 7</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="task-1---práctica" class="level2">
<h2 class="anchored" data-anchor-id="task-1---práctica">Task 1 - Práctica</h2>
<section id="ejercicio-1" class="level3">
<h3 class="anchored" data-anchor-id="ejercicio-1">Ejercicio 1</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cuda.is_available())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cuda</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Definición del modelo</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LeNet5(nn.Module):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LeNet5, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">5</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">6</span>, <span class="dv">16</span>, <span class="dv">5</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">16</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>, <span class="dv">120</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">120</span>, <span class="dv">84</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(<span class="dv">84</span>, <span class="dv">10</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.tanh(F.avg_pool2d(<span class="va">self</span>.conv1(x), <span class="dv">2</span>))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.tanh(F.avg_pool2d(<span class="va">self</span>.conv2(x), <span class="dv">2</span>))</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">16</span><span class="op">*</span><span class="dv">5</span><span class="op">*</span><span class="dv">5</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.fc1(x))</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.fc2(x))</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc3(x)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.log_softmax(x, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Hiperparámetros</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>LR <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformaciones y carga del dataset</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>,), (<span class="fl">0.5</span>,))</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.MNIST(<span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> datasets.MNIST(<span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, transform<span class="op">=</span>transform)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Instancia del modelo, función de pérdida y optimizador</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LeNet5().to(device)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span>LR)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenamiento</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCHS):</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, target) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        data, target <span class="op">=</span> data.to(device), target.to(device)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(data)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(output, target)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_idx <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Train Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> [</span><span class="sc">{</span>batch_idx<span class="op">*</span><span class="bu">len</span>(data)<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(train_loader.dataset)<span class="sc">}</span><span class="ss"> "</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f"(</span><span class="sc">{</span><span class="fl">100.</span> <span class="op">*</span> batch_idx <span class="op">/</span> <span class="bu">len</span>(train_loader)<span class="sc">:.0f}</span><span class="ss">%)]</span><span class="ch">\t</span><span class="ss">Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluación</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data, target <span class="kw">in</span> test_loader:</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>        data, target <span class="op">=</span> data.to(device), target.to(device)</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(data)</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">+=</span> criterion(output, target).item() </span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> output.argmax(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> pred.eq(target.view_as(pred)).<span class="bu">sum</span>().item()</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"(</span><span class="sc">{</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset)<span class="sc">:.0f}</span><span class="ss">%)</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train Epoch: 0 [0/60000 (0%)]   Loss: 2.290354
Train Epoch: 0 [6400/60000 (11%)]   Loss: 2.315570
Train Epoch: 0 [12800/60000 (21%)]  Loss: 2.299078
Train Epoch: 0 [19200/60000 (32%)]  Loss: 2.298903
Train Epoch: 0 [25600/60000 (43%)]  Loss: 2.300027
Train Epoch: 0 [32000/60000 (53%)]  Loss: 2.312724
Train Epoch: 0 [38400/60000 (64%)]  Loss: 2.307347
Train Epoch: 0 [44800/60000 (75%)]  Loss: 2.314235
Train Epoch: 0 [51200/60000 (85%)]  Loss: 2.299103
Train Epoch: 0 [57600/60000 (96%)]  Loss: 2.297892
Train Epoch: 1 [0/60000 (0%)]   Loss: 2.300854
Train Epoch: 1 [6400/60000 (11%)]   Loss: 2.304880
Train Epoch: 1 [12800/60000 (21%)]  Loss: 2.295555
Train Epoch: 1 [19200/60000 (32%)]  Loss: 2.306973
Train Epoch: 1 [25600/60000 (43%)]  Loss: 2.288721
Train Epoch: 1 [32000/60000 (53%)]  Loss: 2.300674
Train Epoch: 1 [38400/60000 (64%)]  Loss: 2.300735
Train Epoch: 1 [44800/60000 (75%)]  Loss: 2.296987
Train Epoch: 1 [51200/60000 (85%)]  Loss: 2.297271
Train Epoch: 1 [57600/60000 (96%)]  Loss: 2.303181
Train Epoch: 2 [0/60000 (0%)]   Loss: 2.297223
Train Epoch: 2 [6400/60000 (11%)]   Loss: 2.307899
Train Epoch: 2 [12800/60000 (21%)]  Loss: 2.305202
Train Epoch: 2 [19200/60000 (32%)]  Loss: 2.299099
Train Epoch: 2 [25600/60000 (43%)]  Loss: 2.278854
Train Epoch: 2 [32000/60000 (53%)]  Loss: 2.305628
Train Epoch: 2 [38400/60000 (64%)]  Loss: 2.292988
Train Epoch: 2 [44800/60000 (75%)]  Loss: 2.284897
Train Epoch: 2 [51200/60000 (85%)]  Loss: 2.301391
Train Epoch: 2 [57600/60000 (96%)]  Loss: 2.292528
Train Epoch: 3 [0/60000 (0%)]   Loss: 2.300167
Train Epoch: 3 [6400/60000 (11%)]   Loss: 2.318235
Train Epoch: 3 [12800/60000 (21%)]  Loss: 2.282169
Train Epoch: 3 [19200/60000 (32%)]  Loss: 2.308214
Train Epoch: 3 [25600/60000 (43%)]  Loss: 2.293639
Train Epoch: 3 [32000/60000 (53%)]  Loss: 2.287900
Train Epoch: 3 [38400/60000 (64%)]  Loss: 2.289978
Train Epoch: 3 [44800/60000 (75%)]  Loss: 2.289389
Train Epoch: 3 [51200/60000 (85%)]  Loss: 2.282530
Train Epoch: 3 [57600/60000 (96%)]  Loss: 2.280149
Train Epoch: 4 [0/60000 (0%)]   Loss: 2.293365
Train Epoch: 4 [6400/60000 (11%)]   Loss: 2.291999
Train Epoch: 4 [12800/60000 (21%)]  Loss: 2.289127
Train Epoch: 4 [19200/60000 (32%)]  Loss: 2.285772
Train Epoch: 4 [25600/60000 (43%)]  Loss: 2.282268
Train Epoch: 4 [32000/60000 (53%)]  Loss: 2.272134
Train Epoch: 4 [38400/60000 (64%)]  Loss: 2.267790
Train Epoch: 4 [44800/60000 (75%)]  Loss: 2.270984
Train Epoch: 4 [51200/60000 (85%)]  Loss: 2.259552
Train Epoch: 4 [57600/60000 (96%)]  Loss: 2.279252
Train Epoch: 5 [0/60000 (0%)]   Loss: 2.265924
Train Epoch: 5 [6400/60000 (11%)]   Loss: 2.263482
Train Epoch: 5 [12800/60000 (21%)]  Loss: 2.271164
Train Epoch: 5 [19200/60000 (32%)]  Loss: 2.255219
Train Epoch: 5 [25600/60000 (43%)]  Loss: 2.227378
Train Epoch: 5 [32000/60000 (53%)]  Loss: 2.241599
Train Epoch: 5 [38400/60000 (64%)]  Loss: 2.201749
Train Epoch: 5 [44800/60000 (75%)]  Loss: 2.225660
Train Epoch: 5 [51200/60000 (85%)]  Loss: 2.214654
Train Epoch: 5 [57600/60000 (96%)]  Loss: 2.207725
Train Epoch: 6 [0/60000 (0%)]   Loss: 2.238866
Train Epoch: 6 [6400/60000 (11%)]   Loss: 2.173890
Train Epoch: 6 [12800/60000 (21%)]  Loss: 2.147619
Train Epoch: 6 [19200/60000 (32%)]  Loss: 2.129619
Train Epoch: 6 [25600/60000 (43%)]  Loss: 2.081799
Train Epoch: 6 [32000/60000 (53%)]  Loss: 2.104464
Train Epoch: 6 [38400/60000 (64%)]  Loss: 2.122292
Train Epoch: 6 [44800/60000 (75%)]  Loss: 2.079769
Train Epoch: 6 [51200/60000 (85%)]  Loss: 2.041947
Train Epoch: 6 [57600/60000 (96%)]  Loss: 1.935064
Train Epoch: 7 [0/60000 (0%)]   Loss: 1.980747
Train Epoch: 7 [6400/60000 (11%)]   Loss: 1.821163
Train Epoch: 7 [12800/60000 (21%)]  Loss: 1.860492
Train Epoch: 7 [19200/60000 (32%)]  Loss: 1.967731
Train Epoch: 7 [25600/60000 (43%)]  Loss: 1.738807
Train Epoch: 7 [32000/60000 (53%)]  Loss: 1.842051
Train Epoch: 7 [38400/60000 (64%)]  Loss: 1.723595
Train Epoch: 7 [44800/60000 (75%)]  Loss: 1.634346
Train Epoch: 7 [51200/60000 (85%)]  Loss: 1.704315
Train Epoch: 7 [57600/60000 (96%)]  Loss: 1.696681
Train Epoch: 8 [0/60000 (0%)]   Loss: 1.585786
Train Epoch: 8 [6400/60000 (11%)]   Loss: 1.460944
Train Epoch: 8 [12800/60000 (21%)]  Loss: 1.504637
Train Epoch: 8 [19200/60000 (32%)]  Loss: 1.538492
Train Epoch: 8 [25600/60000 (43%)]  Loss: 1.371103
Train Epoch: 8 [32000/60000 (53%)]  Loss: 1.488982
Train Epoch: 8 [38400/60000 (64%)]  Loss: 1.280876
Train Epoch: 8 [44800/60000 (75%)]  Loss: 1.339621
Train Epoch: 8 [51200/60000 (85%)]  Loss: 1.340497
Train Epoch: 8 [57600/60000 (96%)]  Loss: 1.295983
Train Epoch: 9 [0/60000 (0%)]   Loss: 1.223771
Train Epoch: 9 [6400/60000 (11%)]   Loss: 1.143815
Train Epoch: 9 [12800/60000 (21%)]  Loss: 1.285403
Train Epoch: 9 [19200/60000 (32%)]  Loss: 1.114302
Train Epoch: 9 [25600/60000 (43%)]  Loss: 1.140909
Train Epoch: 9 [32000/60000 (53%)]  Loss: 1.214866
Train Epoch: 9 [38400/60000 (64%)]  Loss: 1.105295
Train Epoch: 9 [44800/60000 (75%)]  Loss: 1.114371
Train Epoch: 9 [51200/60000 (85%)]  Loss: 0.957275
Train Epoch: 9 [57600/60000 (96%)]  Loss: 1.113677
Train Epoch: 10 [0/60000 (0%)]  Loss: 1.016166
Train Epoch: 10 [6400/60000 (11%)]  Loss: 0.836244
Train Epoch: 10 [12800/60000 (21%)] Loss: 0.917692
Train Epoch: 10 [19200/60000 (32%)] Loss: 0.962960
Train Epoch: 10 [25600/60000 (43%)] Loss: 0.914223
Train Epoch: 10 [32000/60000 (53%)] Loss: 0.935577
Train Epoch: 10 [38400/60000 (64%)] Loss: 0.927864
Train Epoch: 10 [44800/60000 (75%)] Loss: 0.908553
Train Epoch: 10 [51200/60000 (85%)] Loss: 0.985946
Train Epoch: 10 [57600/60000 (96%)] Loss: 0.797681
Train Epoch: 11 [0/60000 (0%)]  Loss: 0.778887
Train Epoch: 11 [6400/60000 (11%)]  Loss: 0.921462
Train Epoch: 11 [12800/60000 (21%)] Loss: 0.739085
Train Epoch: 11 [19200/60000 (32%)] Loss: 0.915735
Train Epoch: 11 [25600/60000 (43%)] Loss: 0.749777
Train Epoch: 11 [32000/60000 (53%)] Loss: 0.927942
Train Epoch: 11 [38400/60000 (64%)] Loss: 0.868798
Train Epoch: 11 [44800/60000 (75%)] Loss: 0.705947
Train Epoch: 11 [51200/60000 (85%)] Loss: 0.867870
Train Epoch: 11 [57600/60000 (96%)] Loss: 0.877646
Train Epoch: 12 [0/60000 (0%)]  Loss: 0.821957
Train Epoch: 12 [6400/60000 (11%)]  Loss: 0.677227
Train Epoch: 12 [12800/60000 (21%)] Loss: 0.888611
Train Epoch: 12 [19200/60000 (32%)] Loss: 0.587170
Train Epoch: 12 [25600/60000 (43%)] Loss: 0.953355
Train Epoch: 12 [32000/60000 (53%)] Loss: 0.589124
Train Epoch: 12 [38400/60000 (64%)] Loss: 0.667878
Train Epoch: 12 [44800/60000 (75%)] Loss: 0.710181
Train Epoch: 12 [51200/60000 (85%)] Loss: 0.603574
Train Epoch: 12 [57600/60000 (96%)] Loss: 0.790573
Train Epoch: 13 [0/60000 (0%)]  Loss: 0.381692
Train Epoch: 13 [6400/60000 (11%)]  Loss: 0.691773
Train Epoch: 13 [12800/60000 (21%)] Loss: 0.644380
Train Epoch: 13 [19200/60000 (32%)] Loss: 0.597041
Train Epoch: 13 [25600/60000 (43%)] Loss: 0.514326
Train Epoch: 13 [32000/60000 (53%)] Loss: 0.674853
Train Epoch: 13 [38400/60000 (64%)] Loss: 0.462263
Train Epoch: 13 [44800/60000 (75%)] Loss: 0.619597
Train Epoch: 13 [51200/60000 (85%)] Loss: 0.621748
Train Epoch: 13 [57600/60000 (96%)] Loss: 0.470695
Train Epoch: 14 [0/60000 (0%)]  Loss: 0.660009
Train Epoch: 14 [6400/60000 (11%)]  Loss: 0.599284
Train Epoch: 14 [12800/60000 (21%)] Loss: 0.528506
Train Epoch: 14 [19200/60000 (32%)] Loss: 0.608190
Train Epoch: 14 [25600/60000 (43%)] Loss: 0.532200
Train Epoch: 14 [32000/60000 (53%)] Loss: 0.468184
Train Epoch: 14 [38400/60000 (64%)] Loss: 0.483214
Train Epoch: 14 [44800/60000 (75%)] Loss: 0.643663
Train Epoch: 14 [51200/60000 (85%)] Loss: 0.454628
Train Epoch: 14 [57600/60000 (96%)] Loss: 0.467120
(87%)
</code></pre>
</div>
</div>
</section>
<section id="ejercicio-2" class="level3">
<h3 class="anchored" data-anchor-id="ejercicio-2">Ejercicio 2</h3>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNet(nn.Module):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capa convolucional 1</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">96</span>, kernel_size<span class="op">=</span><span class="dv">11</span>, stride<span class="op">=</span><span class="dv">4</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu1 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lrn1 <span class="op">=</span> nn.LocalResponseNorm(<span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">1e-4</span>, beta<span class="op">=</span><span class="fl">0.75</span>, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool1 <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capa convolucional 2</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">96</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu2 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lrn2 <span class="op">=</span> nn.LocalResponseNorm(<span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">1e-4</span>, beta<span class="op">=</span><span class="fl">0.75</span>, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool2 <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capa convolucional 3</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Conv2d(<span class="dv">256</span>, <span class="dv">384</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu3 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capa convolucional 4</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv4 <span class="op">=</span> nn.Conv2d(<span class="dv">384</span>, <span class="dv">384</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu4 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capa convolucional 5</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv5 <span class="op">=</span> nn.Conv2d(<span class="dv">384</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu5 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool5 <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Capas completamente conectadas</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc6 <span class="op">=</span> nn.Linear(<span class="dv">256</span> <span class="op">*</span> <span class="dv">6</span> <span class="op">*</span> <span class="dv">6</span>, <span class="dv">4096</span>)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu6 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout6 <span class="op">=</span> nn.Dropout(<span class="fl">0.5</span>)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc7 <span class="op">=</span> nn.Linear(<span class="dv">4096</span>, <span class="dv">4096</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu7 <span class="op">=</span> nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout7 <span class="op">=</span> nn.Dropout(<span class="fl">0.5</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc8 <span class="op">=</span> nn.Linear(<span class="dv">4096</span>, num_classes)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool1(<span class="va">self</span>.lrn1(<span class="va">self</span>.relu1(<span class="va">self</span>.conv1(x))))</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool2(<span class="va">self</span>.lrn2(<span class="va">self</span>.relu2(<span class="va">self</span>.conv2(x))))</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.relu3(<span class="va">self</span>.conv3(x))</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.relu4(<span class="va">self</span>.conv4(x))</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool5(<span class="va">self</span>.relu5(<span class="va">self</span>.conv5(x)))</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(x.size(<span class="dv">0</span>), <span class="dv">256</span> <span class="op">*</span> <span class="dv">6</span> <span class="op">*</span> <span class="dv">6</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout6(<span class="va">self</span>.relu6(<span class="va">self</span>.fc6(x)))</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout7(<span class="va">self</span>.relu7(<span class="va">self</span>.fc7(x)))</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc8(x)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.softmax(x, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para entrenar el modelo</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_loader, criterion, optimizer, num_epochs<span class="op">=</span><span class="dv">30</span>):</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> train_loader:</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            images, labels <span class="op">=</span> images.to(device), labels.to(device)</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item()</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>running_loss<span class="op">/</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Función para evaluar el modelo</span></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, test_loader):</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> test_loader:</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>            images, labels <span class="op">=</span> images.to(device), labels.to(device)</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> correct <span class="op">/</span> total</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Accuracy on test set: </span><span class="sc">{</span>accuracy<span class="sc">}</span><span class="ss">%"</span>)</span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>))</span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torchvision.datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> torchvision.datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AlexNet(num_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>train_model(model, train_loader, criterion, optimizer, num_epochs<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>evaluate_model(model, test_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified
Epoch 1/30, Loss: 2.302589490895381
Epoch 2/30, Loss: 2.3025704125309234
Epoch 3/30, Loss: 2.3025254858729176
Epoch 4/30, Loss: 2.302226912944823
Epoch 5/30, Loss: 2.25119497983352
Epoch 6/30, Loss: 2.213179388619445
Epoch 7/30, Loss: 2.1572559105465783
Epoch 8/30, Loss: 2.111590341533846
Epoch 9/30, Loss: 2.071355868635885
Epoch 10/30, Loss: 2.041391796163281
Epoch 11/30, Loss: 1.9850449238896675
Epoch 12/30, Loss: 1.9442216006996076
Epoch 13/30, Loss: 1.9191369117068513
Epoch 14/30, Loss: 1.886217120815726
Epoch 15/30, Loss: 1.8580890584479817
Epoch 16/30, Loss: 1.833253474948961
Epoch 17/30, Loss: 1.8073494653872517
Epoch 18/30, Loss: 1.7937313595696178
Epoch 19/30, Loss: 1.7717730893808252
Epoch 20/30, Loss: 1.7616859060114303
Epoch 21/30, Loss: 1.758428267048448
Epoch 22/30, Loss: 1.7453365409770585
Epoch 23/30, Loss: 1.732283755031693
Epoch 24/30, Loss: 1.710803150216027
Epoch 25/30, Loss: 1.705536770546223
Epoch 26/30, Loss: 1.6985302739740942
Epoch 27/30, Loss: 1.695783346967624
Epoch 28/30, Loss: 1.6854584367988665
Epoch 29/30, Loss: 1.678006345658656
Epoch 30/30, Loss: 1.6738292587077832
Accuracy on test set: 75.48%</code></pre>
</div>
</div>
<ol type="a">
<li>¿Cuál es la diferencia principal entre ambas arquitecturas?</li>
</ol>
<ul>
<li>LaNet-5: es una arquitectura más simple, contando con 2 capas convolucionales y 3 capas completamente conectadas. Se utiliza la función de ctiación de tanh y existe un menor número de parámetros y menor profundidad que logra AlexNet.</li>
<li>AlexNet: es una arquitectura más compleja, que posee 5 capas convolucionales y 3 capas completamente conectadas. Utiliza la función de activación ReLU e implementa funciones como dropout para evitar el sobreajuste. Permite mayor profundiad y tiene un mayor número de parámetros que LaNet-5.</li>
</ul>
<ol start="2" type="a">
<li>Podría usarse LeNet-5 para un problema como el que resolvió usando AlexNet? ¿Y viceversa?</li>
</ol>
<ul>
<li>Tecnicamente LeNet-5 si se podría usar para problemas que resolvio Alexnet. Sin embargo LeNet-5 tiene un menor capaciddad y profundidad haciendo que no funcione tan bien como Alexnet. Por otro lado, Alexnet si se podría usar para problemas que resolvio LeNet-5, pero al tener una mayor capacidad y profundidad. Esta mayor capacidad puede hace que se use un modelo más complejo para problrmas más sencillos, lo cual puede llevar a un uso innecesario de recursos.</li>
</ul>
<ol start="3" type="a">
<li>Indique claramente qué le pareció más interesante de cada arquitectura</li>
</ol>
<ul>
<li>Lo que más nos llamó la antención de LeNet-5 es la simplicidad del modelo. A pesar de ser considerablemente simple, logró obtener resultados bastante buenos. Por otro lado, lo que más nos llamó la atención de Alexnet es la complejidad del modelo. A pesar de ser un modelo complejo, no logró resultados tan buenos como LeNet-5. Esto nos hace pensar que la complejidad de un modelo no necesariamente se traduce en mejores resultados.</li>
</ul>
<p>Investigue e indique en qué casos son útiles las siguientes arquitecturas, agregue imagenes si esto le ayuda a una mejor comprensión</p>
<ol type="a">
<li>GoogleNet (Inception)</li>
</ol>
<ul>
<li>GoogleNet, también conocida como Inception, es una arquitectura de CNN desarrollada por Google. Se destacó por su profundidad y eficiencia en la utilización de los recursos.</li>
<li>Es útil en casos donde se requieren redes profundas pero se desea mantener un uso eficiente de los recursos computacionales. GoogleNet utiliza una estructura llamada “módulos Inception” que combina múltiples tamaños de filtros de convolución en paralelo, permitiendo la extracción de características a diferentes escalas.</li>
<li>Útil para tareas de clasificación de imágenes, detección de objetos y segmentación semántica.</li>
</ul>
<ol start="2" type="a">
<li>DenseNet (Densely Connected Convolutional Networks)</li>
</ol>
<ul>
<li>DenseNet es una arquitectura de CNN que se caracteriza por su densa conectividad entre capas. Cada capa está conectada directamente con todas las capas subsiguientes.</li>
<li>Es útil en casos donde se desea un mejor flujo de información y gradientes más fuertes a lo largo de la red, lo que facilita el entrenamiento de redes profundas.</li>
<li>Útil para tareas de clasificación de imágenes, detección de objetos y segmentación semántica.</li>
</ul>
<ol start="3" type="a">
<li>MobileNet</li>
</ol>
<ul>
<li>MobileNet es una arquitectura de CNN diseñada para aplicaciones en dispositivos móviles y embebidos con recursos computacionales limitados.</li>
<li>Es útil en casos donde se necesita una red ligera y rápida, como en aplicaciones de visión por computadora en dispositivos móviles.</li>
<li>Útil para tareas de clasificación de imágenes, detección de objetos en tiempo real y otras aplicaciones de visión en dispositivos móviles.</li>
</ul>
<ol start="4" type="a">
<li>EfficientNet</li>
</ol>
<ul>
<li>EfficientNet es una familia de arquitecturas de CNN que buscan optimizar el equilibrio entre el rendimiento y la eficiencia computacional mediante el uso de escalado compuesto.</li>
<li>Es útil en casos donde se desean modelos con un buen rendimiento pero que sean escalables en términos de tamaño y requisitos computacionales.</li>
<li>Útil para una variedad de tareas de visión por computadora, desde clasificación de imágenes hasta detección de objetos y segmentación semántica.</li>
</ul>
<p>¿Cómo la arquitectura de transformers puede ser usada para image recognition?</p>
<p>La arquitectura de Transformers se puede usar en el reconocimiento de imágenes al tratar las imágenes como secuencias de parches y aplicar mecanismos de atención y transformación para capturar información espacial y contextual. Esto se puede hacer al obtener las características, el uso de atención multi-cabeza y agregar información. Los modelos de visión Transformer se entrenan en conjuntos de datos etiquetados, se ajustan finamente en tareas específicas y permiten la transferencia de aprendizaje.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>